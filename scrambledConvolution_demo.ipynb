{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oqA4F-UkZGR"
      },
      "source": [
        "#SETUP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmJb3wNcCBEN"
      },
      "source": [
        "## **Installation**\n",
        "First we need to install the package. Feel free to copy the terminal command for local installation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wK3GigIafc-"
      },
      "outputs": [],
      "source": [
        "!pip3 install --force-reinstall scrambledConvolution@git+https://github.com/tillvogt/scrambledConvolution.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEf1A966CW6l"
      },
      "source": [
        "##**Imports**\n",
        "next to the scrambledConvolution package, numpy and numba are installed as dependencies.\n",
        "For visualizing things we import matplotlib.pyplot.\n",
        "\n",
        "The scrambledConvolution Package can be divided in different Subpackages:\n",
        "\n",
        "\n",
        "*   .layers: the different processinglayers like *'Convolutional'*, *'Dense'*, *'Pooling'* and *'Reshape'*.\n",
        "*   .activations: the different activation Layers like *'Softmax'*, *'Sigmoid'*, *'Tanh'*\n",
        "*   .losses: Lossfunctions like *'RMS'* and *'binary_cross_entropy'*\n",
        "*   .datasets: small sample packages like a shrinked version of MNIST\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msA4IF18avpw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scrambledConvolution.layers import Convolutional\n",
        "from scrambledConvolution.datasets.mnist_loader import load_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfMgM522kfqx"
      },
      "source": [
        "#CONVOLUTIONAL LAYER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRoTT7YAHIc5"
      },
      "source": [
        "##**Loading testdata**\n",
        "\n",
        "Due to the fact, that this whole project is mainly about the Convolutional Layer, we try out some of the corresponding features.\n",
        "\n",
        "So lets import some handwritten digits from MNIST Dataset. We use the build in Dataloader for that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEglApzGbIT4"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test = load_data()\n",
        "\n",
        "#change the picture_index for choosing another example\n",
        "picture_index = 1\n",
        "test_image = x_train[picture_index]\n",
        "\n",
        "plt.imshow(test_image[0], cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evfFi_i3JGRP"
      },
      "source": [
        "##**Using 'Convolution'**\n",
        "\n",
        "Now we instantiate a Convolutional layer. For feeding it with our testdata, just give it as argument, for the *.forward* method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX1nofLsb0Pn"
      },
      "outputs": [],
      "source": [
        "conv1 = Convolutional((1,28,28), 3, 1, type=\"regular\", mix_factor = 0)\n",
        "conv_image = conv1.forward(test_image)\n",
        "\n",
        "plt.imshow(conv_image[0], cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XhLm_g0PDop"
      },
      "source": [
        "As you might see, the image is reduced in size, as well as noisy. The noise comes from the randomly picked biases, when initialising the Layer. So for investigate the kernel variations, we should set them to zero:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hItHvkTEc1yF"
      },
      "outputs": [],
      "source": [
        "conv1.biases = np.zeros(conv1.biases.shape)\n",
        "conv_image = conv1.forward(test_image)\n",
        "\n",
        "plt.imshow(conv_image[0], cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yB5v0Lk1PqrU"
      },
      "source": [
        "##Mix IT UP!##\n",
        "\n",
        "Now after removing noise, let's test the mixing capabilities.\n",
        "Here you can pick one of the different types:\n",
        "*   \"*regular*\" = standard cross-correlation\n",
        "*   \"*retinaMix*\" = the kernel stays in square shape, directs the result of operations to random positions in the resulting image\n",
        "*   \"*kernelMix*\" = in this mode, the kernel is variated. For some of the Operations pixel inside the kernel is redirected to a random position.\n",
        "\n",
        "\n",
        "All the mixing operations depend on the *mix_factor*, wich is a frequency depending on the imagesize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hes39sU3i87k"
      },
      "outputs": [],
      "source": [
        "#setting a mixingfactor\n",
        "mix_factor = 0.5\n",
        "\n",
        "#Instantiate two Concolutional layers\n",
        "conv_retina_mix = Convolutional((1,28,28), 3, 1, type=\"retinaMix\", mix_factor=mix_factor)\n",
        "conv_kernel_mix = Convolutional((1,28,28), 3, 1, type=\"kernelMix\", mix_factor=mix_factor)\n",
        "conv_conc_mix = Convolutional((1,28,28), 3, 1, type=\"concMix\", mix_factor=mix_factor)\n",
        "\n",
        "#Setting same weights for better comparison\n",
        "conv_kernel_mix.kernels = conv_retina_mix.kernels\n",
        "conv_conc_mix.kernels = conv_retina_mix.kernels\n",
        "\n",
        "#Setting biases to zero\n",
        "conv_retina_mix.biases = np.zeros(conv_retina_mix.biases.shape)\n",
        "conv_kernel_mix.biases = np.zeros(conv_kernel_mix.biases.shape)\n",
        "conv_conc_mix.biases = np.zeros(conv_conc_mix.biases.shape)\n",
        "\n",
        "#feeding it with the testimage\n",
        "retina_mix_image = conv_retina_mix.forward(test_image)\n",
        "kernel_mix_image = conv_kernel_mix.forward(test_image)\n",
        "conc_mix_image = conv_conc_mix.forward(test_image)\n",
        "\n",
        "######plotting#####\n",
        "fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
        "\n",
        "axs[0].imshow(retina_mix_image[0], cmap=\"gray\")\n",
        "axs[0].title.set_text(f\"Retinamix: {mix_factor}\")\n",
        "axs[0].axis(\"off\")\n",
        "\n",
        "axs[1].imshow(kernel_mix_image[0], cmap=\"gray\")\n",
        "axs[1].title.set_text(f\"Kernelmix: {mix_factor}\")\n",
        "axs[1].axis(\"off\")\n",
        "\n",
        "axs[2].imshow(conc_mix_image[0], cmap=\"gray\")\n",
        "axs[2].title.set_text(f\"Concentrationmix: {mix_factor}\")\n",
        "axs[2].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ap-tPOik6RD"
      },
      "source": [
        "#TRAIN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPnwZnGKrUau"
      },
      "source": [
        "##Essential imports\n",
        "\n",
        "For training a Network, one has to make some further imports first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqMh1Nk2sLiD"
      },
      "outputs": [],
      "source": [
        "from scrambledConvolution import train\n",
        "from scrambledConvolution.losses import mse, mse_prime\n",
        "from scrambledConvolution.activations import Sigmoid, Softmax\n",
        "from scrambledConvolution.layers import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp5i-ptEsMg0"
      },
      "source": [
        "##Building Network\n",
        "\n",
        "Now we are able to build a Network as a list of the different layer Classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB0Gc-uDpedF"
      },
      "outputs": [],
      "source": [
        "convolution_type = \"kernelMix\"\n",
        "mix_factor = 0\n",
        "\n",
        "\n",
        "network = [\n",
        "      Convolutional((1, 28, 28), 5, 5, type=convolution_type, mix_factor=mix_factor),\n",
        "      Sigmoid(),\n",
        "      Pooling(),\n",
        "      Convolutional((5, 12, 12), 5, 5, type=convolution_type, mix_factor=mix_factor),\n",
        "      Sigmoid(),\n",
        "      Pooling(),\n",
        "      Reshape((5,4,4), ((5*4*4), 1)),\n",
        "      Dense(80, 32),\n",
        "      Sigmoid(),\n",
        "      Dense(32,10),\n",
        "      Softmax()\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Do you even lift?\n",
        "\n",
        "Fortunatly the pc trains for us...\n",
        "\n",
        "Just use the *train()* function and set the essential parameters. A fews things to explain:\n",
        "\n",
        "*   *friction:* There is no real optimizier implemented. However, to overcome saddle points 'inertia' is implemented. the *friction* parameter is the factor of the previous gradient. I recomment a value between 0 (no inertia) to 1.\n",
        "*   *weight-saving:* If this is TRUE, the weights and biases of convolutional Layers are saved in a .csv at the end of the training"
      ],
      "metadata": {
        "id": "25h_o9XSZEbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = train(mix_factor, network, mse, mse_prime, x_train, y_train, x_test, y_test, epochs = 10, batch_size = 16, )"
      ],
      "metadata": {
        "id": "DboEzntzZUyB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}